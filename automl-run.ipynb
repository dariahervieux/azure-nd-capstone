{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Workspace set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "gather": {
     "logged": 1600358054485
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK version: 1.20.0\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "from azureml.core.experiment import Experiment\n",
    "from azureml.core.workspace import Workspace\n",
    "from azureml.core.dataset import Dataset\n",
    "\n",
    "import logging\n",
    "\n",
    "\n",
    "# Check core SDK version number\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Workspace object for the existing ML Workspace, from the configuration file `config.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "gather": {
     "logged": 1599176159666
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quick-starts-ws-137658\n",
      "aml-quickstarts-137658\n",
      "southcentralus\n",
      "2c48c51c-bd47-40d4-abbe-fb8eabd19c8c\n"
     ]
    }
   ],
   "source": [
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a *new* ML Experiment in the ML Workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "gather": {
     "logged": 1599176198129
    }
   },
   "outputs": [],
   "source": [
    "experiment_name = 'azure-nd-project-capstone'\n",
    "project_folder = './automl-run-capstone-project'\n",
    "\n",
    "experiment = Experiment(ws, experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a new cluster for model training.\n",
    "If the cluster with the specified name already exists, use it.\n",
    "The desired model is based on Regression analysis, without usage of Deep "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "gather": {
     "logged": 1599176275878
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cluster, use it.\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.core.compute import ComputeTarget\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "#cluster_name = \"cluster-nd-capstone\"\n",
    "cluster_name = \"auto-ml\"\n",
    "\n",
    "# Verify that cluster does not exist already\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS12_V2',\n",
    "                                                           #vm_priority = 'lowpriority', # optional\n",
    "                                                           max_nodes=4, min_nodes=1)\n",
    "    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "\n",
    "compute_target.wait_for_completion(show_output=True, min_node_count= None, timeout_in_minutes = 10)\n",
    "# For a more detailed view of current AmlCompute status, use get_status()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload and register the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean-up the dataset\n",
    "Since we are comparing the results of the AutoML run and the HyperDrive run, it's better to work on the same data set, to be able to compare the performance of each model without the influence of feature engineering. So we are cleaning the dataset using a python script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.cleansing import clean_data\n",
    "import pandas as pd\n",
    "\n",
    "def get_cleaned_dataset():\n",
    "    found = False\n",
    "    ds_key = \"openfoodfacts\"\n",
    "    description_text = \"Data extracted from OpenFoodFacts open source database.\"\n",
    "\n",
    "    if ds_key in ws.datasets.keys(): \n",
    "        found = True\n",
    "        ds_cleaned = ws.datasets[ds_key] \n",
    "\n",
    "    # Otherwise, create it from the file\n",
    "    if not found:\n",
    "        #Reading a json lines file into a DataFrame\n",
    "        data = pd.read_json('./eda/foods-features-v3.json', lines=True)\n",
    "        # DataFrame with cleaned data\n",
    "        data_cleaned = clean_data(data)\n",
    "        exported_df = 'cleaned-openfoodfacts.parquet'\n",
    "        cleaned_data.to_parquet(exported_df);\n",
    "        # Register Dataset in Workspace using experimental funcionality to upload and register pandas dataframe at once\n",
    "        ds_cleaned = TabularDatasetFactory.register_pandas_dataframe(dataframe=cleaned_data,\n",
    "                                                                     target=(ws.get_default_datastore(), exported_df),\n",
    "                                                                     name=ds_key, description=description_text,\n",
    "                                                                     show_progress=True)\n",
    "    return ds_cleaned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 1 files\n",
      "Uploading ./eda/foods-features-10000-str.json\n",
      "Uploaded ./eda/foods-features-10000-str.json, 1 files out of an estimated total of 1\n",
      "Uploaded 1 files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_1f736f1fbe9a401a9fff1c01141805a6"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the datastore to upload prepared data\n",
    "blob_store = ws.get_default_datastore()\n",
    "# upload the files to default datastore, DataReference\n",
    "blob_store.upload_files(#files=json_files,\n",
    "                       files=['./eda/foods-features-v3.json'], \n",
    "                       target_path='capstone', relative_root='eda',\n",
    "                       show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "gather": {
     "logged": 1599176333406
    }
   },
   "outputs": [],
   "source": [
    "from azureml.data.dataset_factory import TabularDatasetFactory\n",
    "\n",
    "# Try to load the dataset from the Workspace. Otherwise, create it from the file\n",
    "found = False\n",
    "key = \"openfoodfacts\"\n",
    "description_text = \"Data extracted from OpenFoodFacts open source database.\"\n",
    "\n",
    "\n",
    "if key in ws.datasets.keys(): \n",
    "        found = True\n",
    "        print(f'Dataset {key} found, use it.')\n",
    "        dataset = ws.datasets[key] \n",
    "\n",
    "if not found:\n",
    "# Create tabular dataset from the local JSON file\n",
    "blob_file = blob_store.path('capstone/foods-features-v3.json')\n",
    "dataset = TabularDatasetFactory.from_json_lines_files(path=blob_file)      \n",
    "# Register Dataset in Workspace\n",
    "dataset = dataset.register(workspace=ws,\n",
    "                           name=key,\n",
    "                           description=description_text,\n",
    "                           create_new_version=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pandas dataframe\n",
    "df = dataset.to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore data - take first 5 elements\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>additives_n</th>\n",
       "      <th>nutriscore_grade</th>\n",
       "      <th>popularity_key</th>\n",
       "      <th>salt_level</th>\n",
       "      <th>fat_level</th>\n",
       "      <th>saturated_fat_level</th>\n",
       "      <th>sugar_level</th>\n",
       "      <th>vegan</th>\n",
       "      <th>vegeterian</th>\n",
       "      <th>palm_oil</th>\n",
       "      <th>brand</th>\n",
       "      <th>packagin_shape</th>\n",
       "      <th>packagin_material</th>\n",
       "      <th>serving_quantity_g</th>\n",
       "      <th>categories_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8710908960864</td>\n",
       "      <td>1</td>\n",
       "      <td>d</td>\n",
       "      <td>119999900233</td>\n",
       "      <td>high</td>\n",
       "      <td>moderate</td>\n",
       "      <td>moderate</td>\n",
       "      <td>moderate</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>knorr</td>\n",
       "      <td>brick</td>\n",
       "      <td>cardboard</td>\n",
       "      <td>100.0</td>\n",
       "      <td>plant-based-foods-and-beverages, plant-based-f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5413548283128</td>\n",
       "      <td>3</td>\n",
       "      <td>e</td>\n",
       "      <td>119999000228</td>\n",
       "      <td>low</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>kinder</td>\n",
       "      <td>None</td>\n",
       "      <td>pp-polypropylene</td>\n",
       "      <td>5.0</td>\n",
       "      <td>snacks, sweet-snacks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3274080005003</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>19999996494</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>cristaline</td>\n",
       "      <td>bottle</td>\n",
       "      <td>pet-polyethylene-terephthalate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>beverages, waters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7622210449283</td>\n",
       "      <td>3</td>\n",
       "      <td>c</td>\n",
       "      <td>19999994551</td>\n",
       "      <td>low</td>\n",
       "      <td>moderate</td>\n",
       "      <td>low</td>\n",
       "      <td>moderate</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>lu</td>\n",
       "      <td>film</td>\n",
       "      <td>plastic</td>\n",
       "      <td>20.0</td>\n",
       "      <td>snacks, sweet-snacks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3017620422003</td>\n",
       "      <td>1</td>\n",
       "      <td>e</td>\n",
       "      <td>19999993283</td>\n",
       "      <td>low</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>ferrero</td>\n",
       "      <td>jar</td>\n",
       "      <td>glass</td>\n",
       "      <td>15.0</td>\n",
       "      <td>spreads, breakfasts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             _id  additives_n nutriscore_grade  popularity_key salt_level  \\\n",
       "0  8710908960864            1                d    119999900233       high   \n",
       "1  5413548283128            3                e    119999000228        low   \n",
       "2  3274080005003            0                a     19999996494        low   \n",
       "3  7622210449283            3                c     19999994551        low   \n",
       "4  3017620422003            1                e     19999993283        low   \n",
       "\n",
       "  fat_level saturated_fat_level sugar_level  vegan  vegeterian  palm_oil  \\\n",
       "0  moderate            moderate    moderate  False       False     False   \n",
       "1      high                high        high  False       False      True   \n",
       "2       low                 low         low   True       False     False   \n",
       "3  moderate                 low    moderate  False       False      True   \n",
       "4      high                high        high  False       False      True   \n",
       "\n",
       "        brand packagin_shape               packagin_material  \\\n",
       "0       knorr          brick                       cardboard   \n",
       "1      kinder           None                pp-polypropylene   \n",
       "2  cristaline         bottle  pet-polyethylene-terephthalate   \n",
       "3          lu           film                         plastic   \n",
       "4     ferrero            jar                           glass   \n",
       "\n",
       "   serving_quantity_g                                    categories_list  \n",
       "0               100.0  plant-based-foods-and-beverages, plant-based-f...  \n",
       "1                 5.0                               snacks, sweet-snacks  \n",
       "2                 NaN                                  beverages, waters  \n",
       "3                20.0                               snacks, sweet-snacks  \n",
       "4                15.0                                spreads, breakfasts  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# obtain data statistics for each column\n",
    "df.describe(include='all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of data for each column , devided in 3 bins\n",
    "hist = df.hist(bins=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gather": {
     "logged": 1599176373121
    }
   },
   "source": [
    "## AutoML run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = get_cleaned_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "\"\"\" Creates(if doesn't exist) a new folder with 'folder_name' under 'project_folder'\n",
    "    and copies 'file_names_to_copy' from the 'project_folder' into 'folder_name'\n",
    "\"\"\"\n",
    "def create_folder(project_folder, folder_name, *file_names_to_copy):\n",
    "    new_folder = os.path.join(project_folder, folder_name)\n",
    "    os.makedirs(new_folder, exist_ok=True)\n",
    "\n",
    "    if file_names_to_copy:\n",
    "        for name in file_names_to_copy:\n",
    "            shutil.copy(name, new_folder)\n",
    "    \n",
    "    return new_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "gather": {
     "logged": 1599176419046
    }
   },
   "outputs": [],
   "source": [
    "from azureml.train.automl import AutoMLConfig\n",
    "auto_ml_directory_name = 'auto_ml_run'\n",
    "\n",
    "auto_ml_directory = create_folder(project_folder, auto_ml_directory_name)\n",
    "\n",
    "automl_settings = {\n",
    "    \"experiment_timeout_minutes\": 20, #15 minutes is the minimum\n",
    "    \"enable_early_stopping\": True,\n",
    "    \"primary_metric\": 'r2_score', # the same as hyperdrive\n",
    "    \"featurization\": 'auto',\n",
    "    \"verbosity\": logging.DEBUG,\n",
    "    \"n_cross_validations\": 5\n",
    "}\n",
    "\n",
    "automl_config = AutoMLConfig(compute_target=compute_target,\n",
    "                             max_concurrent_iterations=3, #4 nodes\n",
    "                             task= \"regression\",\n",
    "                             training_data=dataset,\n",
    "                             label_column_name=\"popularity_key\",\n",
    "                             debug_log = \"automl_errors.log\",\n",
    "                             path = auto_ml_directory,\n",
    "                             enable_onnx_compatible_models=True,\n",
    "                             **automl_settings\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "gather": {
     "logged": 1599176501323
    },
    "tags": [
     "automlstep-remarks-sample1"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on remote.\n",
      "No run_configuration provided, running on auto-ml with default configuration\n",
      "Running on remote compute: auto-ml\n",
      "Parent Run ID: AutoML_f9cbc5c2-03b1-4f55-bdce-6ce77f90673b\n",
      "\n",
      "Current status: FeaturesGeneration. Generating features for the dataset.\n",
      "Current status: DatasetCrossValidationSplit. Generating individually featurized CV splits.\n",
      "Current status: ModelSelection. Beginning model selection.\n",
      "\n",
      "****************************************************************************************************\n",
      "DATA GUARDRAILS: \n",
      "\n",
      "TYPE:         Cross validation\n",
      "STATUS:       DONE\n",
      "DESCRIPTION:  Each iteration of the trained model was validated through cross-validation.\n",
      "              \n",
      "DETAILS:      \n",
      "+---------------------------------+\n",
      "|Number of folds                  |\n",
      "+=================================+\n",
      "|3                                |\n",
      "+---------------------------------+\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "TYPE:         Missing feature values imputation\n",
      "STATUS:       DONE\n",
      "DESCRIPTION:  If the missing values are expected, let the run complete. Otherwise cancel the current run and use a script to customize the handling of missing feature values that may be more appropriate based on the data type and business requirement.\n",
      "              Learn more about missing value imputation: https://aka.ms/AutomatedMLFeaturization\n",
      "DETAILS:      \n",
      "+---------------------------------+---------------------------------+---------------------------------+\n",
      "|Column name                      |Missing value count              |Imputation type                  |\n",
      "+=================================+=================================+=================================+\n",
      "|salt_level                       |26                               |                                 |\n",
      "|fat_level                        |47                               |                                 |\n",
      "|saturated_fat_level              |47                               |                                 |\n",
      "|sugar_level                      |47                               |                                 |\n",
      "|brand                            |4                                |                                 |\n",
      "|packagin_shape                   |1910                             |                                 |\n",
      "|packagin_material                |902                              |                                 |\n",
      "|serving_quantity_g               |3390                             |mean                             |\n",
      "+---------------------------------+---------------------------------+---------------------------------+\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "TYPE:         High cardinality feature detection\n",
      "STATUS:       DONE\n",
      "DESCRIPTION:  High cardinality features were detected in your inputs and handled.\n",
      "              Learn more about high cardinality feature handling: https://aka.ms/AutomatedMLFeaturization\n",
      "DETAILS:      High cardinality features refer to columns that contain a large percentage of unique values.\n",
      "+---------------------------------+---------------------------------+\n",
      "|Column name                      |Column Content Type              |\n",
      "+=================================+=================================+\n",
      "|brand                            |categorical_hash                 |\n",
      "|categories_list                  |categorical_hash                 |\n",
      "+---------------------------------+---------------------------------+\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "****************************************************************************************************\n",
      "ITERATION: The iteration being evaluated.\n",
      "PIPELINE: A summary description of the pipeline being evaluated.\n",
      "DURATION: Time taken for the current iteration.\n",
      "METRIC: The result of computing score on the fitted pipeline.\n",
      "BEST: The best observed score thus far.\n",
      "****************************************************************************************************\n",
      "\n",
      " ITERATION   PIPELINE                                       DURATION      METRIC      BEST\n",
      "         1   MaxAbsScaler XGBoostRegressor                  0:01:10       0.0165    0.0165\n",
      "         0   MaxAbsScaler LightGBM                          0:01:18       0.0115    0.0115\n",
      "         3   MaxAbsScaler DecisionTree                      0:01:08       0.0090    0.0090\n",
      "         5   MaxAbsScaler DecisionTree                      0:01:08       0.0093    0.0090\n",
      "         6   MaxAbsScaler DecisionTree                      0:01:08       0.0097    0.0090\n",
      "         2   StandardScalerWrapper ElasticNet               0:05:10       0.0111    0.0090\n",
      "         4   MaxAbsScaler ElasticNet                        0:04:48       0.0105    0.0090\n",
      "         7   MaxAbsScaler DecisionTree                      0:01:07       0.0093    0.0090\n",
      "         9   MaxAbsScaler DecisionTree                      0:01:07       0.0097    0.0090\n",
      "         8   MaxAbsScaler DecisionTree                      0:01:18       0.0090    0.0090\n",
      "        10   MaxAbsScaler DecisionTree                      0:01:05       0.0093    0.0090\n",
      "        11   MaxAbsScaler DecisionTree                      0:01:05       0.0097    0.0090\n",
      "        12   MaxAbsScaler DecisionTree                      0:01:13       0.0090    0.0090\n",
      "        13   StandardScalerWrapper DecisionTree             0:01:13       0.0093    0.0090\n",
      "        14   MaxAbsScaler DecisionTree                      0:01:13       0.0088    0.0088\n",
      "        15   MaxAbsScaler DecisionTree                      0:01:12       0.0089    0.0088\n",
      "        16   MaxAbsScaler SGD                               0:01:16       0.0107    0.0088\n",
      "        17   MaxAbsScaler DecisionTree                      0:01:09       0.0097    0.0088\n",
      "        18   MaxAbsScaler DecisionTree                      0:01:06       0.0088    0.0088\n",
      "        19   MaxAbsScaler DecisionTree                      0:01:02       0.0090    0.0088\n",
      "        20   MaxAbsScaler SGD                               0:01:12       0.0103    0.0088\n",
      "        21   MaxAbsScaler DecisionTree                      0:01:06       0.0097    0.0088\n",
      "        22   MaxAbsScaler DecisionTree                      0:01:08       0.0096    0.0088\n",
      "        23   MaxAbsScaler DecisionTree                      0:01:09       0.0097    0.0088\n",
      "        24   MaxAbsScaler DecisionTree                      0:01:06       0.0097    0.0088\n",
      "        25   MaxAbsScaler DecisionTree                      0:01:03       0.0086    0.0086\n",
      "        27   MaxAbsScaler DecisionTree                      0:01:08       0.0092    0.0086\n",
      "        28   MaxAbsScaler DecisionTree                      0:01:08       0.0097    0.0086\n",
      "        26   MaxAbsScaler RandomForest                      0:01:33       0.0092    0.0086\n",
      "        29   MaxAbsScaler GradientBoosting                  0:01:16       0.0085    0.0085\n",
      "        30   MaxAbsScaler DecisionTree                      0:01:06       0.0087    0.0085\n",
      "        31   MaxAbsScaler DecisionTree                      0:01:05       0.0097    0.0085\n",
      "        32   MaxAbsScaler RandomForest                      0:01:09       0.0086    0.0085\n",
      "        33   MaxAbsScaler LightGBM                          0:01:10       0.0089    0.0085\n",
      "        34   MaxAbsScaler RandomForest                      0:01:08       0.0086    0.0085\n",
      "        35   MaxAbsScaler GradientBoosting                  0:01:09       0.0083    0.0083\n",
      "        36   MaxAbsScaler RandomForest                      0:01:15       0.0088    0.0083\n",
      "        37   MaxAbsScaler DecisionTree                      0:01:05       0.0097    0.0083\n",
      "        38   MaxAbsScaler RandomForest                      0:01:28       0.0087    0.0083\n",
      "        39   MaxAbsScaler RandomForest                      0:01:26       0.0088    0.0083\n",
      "        40   MaxAbsScaler GradientBoosting                  0:01:25       0.0083    0.0083\n",
      "        41   MaxAbsScaler RandomForest                      0:01:15       0.0091    0.0083\n",
      "        42   MaxAbsScaler ExtremeRandomTrees                0:01:14       0.0088    0.0083\n",
      "        43   MaxAbsScaler ExtremeRandomTrees                0:01:32       0.0091    0.0083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        45   SparseNormalizer GradientBoosting              0:01:17       0.0086    0.0083\n",
      "        44   MaxAbsScaler ExtremeRandomTrees                0:01:42       0.0090    0.0083\n",
      "        46   MaxAbsScaler RandomForest                      0:01:34       0.0086    0.0083\n",
      "        48   MaxAbsScaler RandomForest                      0:01:13       0.0086    0.0083\n",
      "        47   MaxAbsScaler RandomForest                      0:01:36       0.0085    0.0083\n",
      "        49   MaxAbsScaler RandomForest                      0:01:05       0.0084    0.0083\n",
      "        50   MaxAbsScaler GradientBoosting                  0:01:06       0.0083    0.0083\n",
      "        51   MaxAbsScaler ExtremeRandomTrees                0:01:29       0.0086    0.0083\n",
      "        52   MaxAbsScaler ExtremeRandomTrees                0:01:12       0.0086    0.0083\n",
      "        53   MaxAbsScaler ExtremeRandomTrees                0:01:17       0.0092    0.0083\n",
      "        54   MaxAbsScaler LightGBM                          0:01:05       0.0088    0.0083\n",
      "        55   MaxAbsScaler GradientBoosting                  0:01:04       0.0085    0.0083\n",
      "        56   MaxAbsScaler RandomForest                      0:01:15       0.0084    0.0083\n",
      "        58   MaxAbsScaler RandomForest                      0:01:19       0.0085    0.0083\n",
      "        57   MaxAbsScaler ExtremeRandomTrees                0:02:17       0.0083    0.0083\n",
      "        59   MaxAbsScaler RandomForest                      0:01:17       0.0086    0.0083\n",
      "        60   SparseNormalizer GradientBoosting              0:01:16       0.0084    0.0083\n",
      "        61   MaxAbsScaler RandomForest                      0:01:16       0.0085    0.0083\n",
      "        62   MaxAbsScaler RandomForest                      0:01:30       0.0085    0.0083\n",
      "        64                                                  0:00:37          nan    0.0083\n",
      "        63   MaxAbsScaler RandomForest                      0:00:58          nan    0.0083\n",
      "        65    VotingEnsemble                                0:02:02       0.0083    0.0083\n"
     ]
    }
   ],
   "source": [
    "auto_ml_run = experiment.submit(automl_config, show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'runId': 'AutoML_f9cbc5c2-03b1-4f55-bdce-6ce77f90673b',\n",
       " 'target': 'auto-ml',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2021-02-06T19:26:41.526021Z',\n",
       " 'endTimeUtc': '2021-02-06T20:15:49.81895Z',\n",
       " 'properties': {'num_iterations': '1000',\n",
       "  'training_type': 'TrainFull',\n",
       "  'acquisition_function': 'EI',\n",
       "  'primary_metric': 'normalized_root_mean_squared_error',\n",
       "  'train_split': '0',\n",
       "  'acquisition_parameter': '0',\n",
       "  'num_cross_validation': None,\n",
       "  'target': 'auto-ml',\n",
       "  'AMLSettingsJsonString': '{\"path\":null,\"name\":\"azure-nd-project-capstone\",\"subscription_id\":\"2c48c51c-bd47-40d4-abbe-fb8eabd19c8c\",\"resource_group\":\"aml-quickstarts-137658\",\"workspace_name\":\"quick-starts-ws-137658\",\"region\":\"southcentralus\",\"compute_target\":\"auto-ml\",\"spark_service\":null,\"azure_service\":\"remote\",\"many_models\":false,\"pipeline_fetch_max_batch_size\":1,\"iterations\":1000,\"primary_metric\":\"normalized_root_mean_squared_error\",\"task_type\":\"regression\",\"data_script\":null,\"validation_size\":0.0,\"n_cross_validations\":null,\"y_min\":null,\"y_max\":null,\"num_classes\":null,\"featurization\":\"auto\",\"_ignore_package_version_incompatibilities\":false,\"is_timeseries\":false,\"max_cores_per_iteration\":1,\"max_concurrent_iterations\":3,\"iteration_timeout_minutes\":null,\"mem_in_mb\":null,\"enforce_time_on_windows\":false,\"experiment_timeout_minutes\":8640,\"experiment_exit_score\":null,\"whitelist_models\":null,\"blacklist_algos\":[\"TensorFlowDNN\",\"TensorFlowLinearRegressor\"],\"supported_models\":[\"KNN\",\"OnlineGradientDescentRegressor\",\"TensorFlowDNN\",\"LightGBM\",\"LassoLars\",\"DecisionTree\",\"ExtremeRandomTrees\",\"XGBoostRegressor\",\"FastLinearRegressor\",\"SGD\",\"ElasticNet\",\"TensorFlowLinearRegressor\",\"GradientBoosting\",\"RandomForest\"],\"auto_blacklist\":true,\"blacklist_samples_reached\":false,\"exclude_nan_labels\":true,\"verbosity\":20,\"_debug_log\":\"azureml_automl.log\",\"show_warnings\":false,\"model_explainability\":true,\"service_url\":null,\"sdk_url\":null,\"sdk_packages\":null,\"enable_onnx_compatible_models\":true,\"enable_split_onnx_featurizer_estimator_models\":false,\"vm_type\":\"STANDARD_D2_V2\",\"telemetry_verbosity\":20,\"send_telemetry\":true,\"enable_dnn\":false,\"scenario\":\"SDK-1.13.0\",\"environment_label\":null,\"force_text_dnn\":false,\"enable_feature_sweeping\":false,\"enable_early_stopping\":true,\"early_stopping_n_iters\":10,\"metrics\":null,\"enable_ensembling\":true,\"enable_stack_ensembling\":false,\"ensemble_iterations\":15,\"enable_tf\":false,\"enable_subsampling\":null,\"subsample_seed\":null,\"enable_nimbusml\":false,\"enable_streaming\":false,\"force_streaming\":false,\"track_child_runs\":true,\"allowed_private_models\":[],\"label_column_name\":\"popularity_key\",\"weight_column_name\":null,\"cv_split_column_names\":null,\"enable_local_managed\":false,\"_local_managed_run_id\":null,\"cost_mode\":1,\"lag_length\":0,\"metric_operation\":\"minimize\",\"preprocess\":true}',\n",
       "  'DataPrepJsonString': '{\\\\\"training_data\\\\\": \\\\\"{\\\\\\\\\\\\\"blocks\\\\\\\\\\\\\": [{\\\\\\\\\\\\\"id\\\\\\\\\\\\\": \\\\\\\\\\\\\"6b03bd03-875b-4e52-b877-599eedd2d1c0\\\\\\\\\\\\\", \\\\\\\\\\\\\"type\\\\\\\\\\\\\": \\\\\\\\\\\\\"Microsoft.DPrep.GetDatastoreFilesBlock\\\\\\\\\\\\\", \\\\\\\\\\\\\"arguments\\\\\\\\\\\\\": {\\\\\\\\\\\\\"datastores\\\\\\\\\\\\\": [{\\\\\\\\\\\\\"datastoreName\\\\\\\\\\\\\": \\\\\\\\\\\\\"workspaceblobstore\\\\\\\\\\\\\", \\\\\\\\\\\\\"path\\\\\\\\\\\\\": \\\\\\\\\\\\\"capstone/foods-features-10000-str.json\\\\\\\\\\\\\", \\\\\\\\\\\\\"resourceGroup\\\\\\\\\\\\\": \\\\\\\\\\\\\"aml-quickstarts-137658\\\\\\\\\\\\\", \\\\\\\\\\\\\"subscription\\\\\\\\\\\\\": \\\\\\\\\\\\\"2c48c51c-bd47-40d4-abbe-fb8eabd19c8c\\\\\\\\\\\\\", \\\\\\\\\\\\\"workspaceName\\\\\\\\\\\\\": \\\\\\\\\\\\\"quick-starts-ws-137658\\\\\\\\\\\\\"}]}, \\\\\\\\\\\\\"localData\\\\\\\\\\\\\": {}, \\\\\\\\\\\\\"isEnabled\\\\\\\\\\\\\": true, \\\\\\\\\\\\\"name\\\\\\\\\\\\\": null, \\\\\\\\\\\\\"annotation\\\\\\\\\\\\\": null}, {\\\\\\\\\\\\\"id\\\\\\\\\\\\\": \\\\\\\\\\\\\"914ef365-7917-4b89-99b9-b37872a6b22e\\\\\\\\\\\\\", \\\\\\\\\\\\\"type\\\\\\\\\\\\\": \\\\\\\\\\\\\"Microsoft.DPrep.ParseJsonLinesBlock\\\\\\\\\\\\\", \\\\\\\\\\\\\"arguments\\\\\\\\\\\\\": {\\\\\\\\\\\\\"fileEncoding\\\\\\\\\\\\\": 0}, \\\\\\\\\\\\\"localData\\\\\\\\\\\\\": {}, \\\\\\\\\\\\\"isEnabled\\\\\\\\\\\\\": true, \\\\\\\\\\\\\"name\\\\\\\\\\\\\": null, \\\\\\\\\\\\\"annotation\\\\\\\\\\\\\": null}, {\\\\\\\\\\\\\"id\\\\\\\\\\\\\": \\\\\\\\\\\\\"91b33232-1a64-4cb9-907b-f2ed2651fdfc\\\\\\\\\\\\\", \\\\\\\\\\\\\"type\\\\\\\\\\\\\": \\\\\\\\\\\\\"Microsoft.DPrep.DropColumnsBlock\\\\\\\\\\\\\", \\\\\\\\\\\\\"arguments\\\\\\\\\\\\\": {\\\\\\\\\\\\\"columns\\\\\\\\\\\\\": {\\\\\\\\\\\\\"type\\\\\\\\\\\\\": 0, \\\\\\\\\\\\\"details\\\\\\\\\\\\\": {\\\\\\\\\\\\\"selectedColumns\\\\\\\\\\\\\": [\\\\\\\\\\\\\"Path\\\\\\\\\\\\\"]}}}, \\\\\\\\\\\\\"localData\\\\\\\\\\\\\": {}, \\\\\\\\\\\\\"isEnabled\\\\\\\\\\\\\": true, \\\\\\\\\\\\\"name\\\\\\\\\\\\\": null, \\\\\\\\\\\\\"annotation\\\\\\\\\\\\\": null}], \\\\\\\\\\\\\"inspectors\\\\\\\\\\\\\": [], \\\\\\\\\\\\\"meta\\\\\\\\\\\\\": {\\\\\\\\\\\\\"savedDatasetId\\\\\\\\\\\\\": \\\\\\\\\\\\\"5f265361-3774-4ccb-bc48-6ad5bd6b46fc\\\\\\\\\\\\\", \\\\\\\\\\\\\"datasetType\\\\\\\\\\\\\": \\\\\\\\\\\\\"tabular\\\\\\\\\\\\\", \\\\\\\\\\\\\"subscriptionId\\\\\\\\\\\\\": \\\\\\\\\\\\\"2c48c51c-bd47-40d4-abbe-fb8eabd19c8c\\\\\\\\\\\\\", \\\\\\\\\\\\\"workspaceId\\\\\\\\\\\\\": \\\\\\\\\\\\\"b4c504f6-4565-4921-b69e-b6b0a658e792\\\\\\\\\\\\\", \\\\\\\\\\\\\"workspaceLocation\\\\\\\\\\\\\": \\\\\\\\\\\\\"southcentralus\\\\\\\\\\\\\"}}\\\\\", \\\\\"activities\\\\\": 0}',\n",
       "  'EnableSubsampling': None,\n",
       "  'runTemplate': 'AutoML',\n",
       "  'azureml.runsource': 'automl',\n",
       "  'display_task_type': 'regression',\n",
       "  'dependencies_versions': '{\"azureml-widgets\": \"1.20.0\", \"azureml-train\": \"1.20.0\", \"azureml-train-restclients-hyperdrive\": \"1.20.0\", \"azureml-train-core\": \"1.20.0\", \"azureml-train-automl\": \"1.20.0\", \"azureml-train-automl-runtime\": \"1.20.0\", \"azureml-train-automl-client\": \"1.20.0\", \"azureml-tensorboard\": \"1.20.0\", \"azureml-telemetry\": \"1.20.0\", \"azureml-sdk\": \"1.20.0\", \"azureml-samples\": \"0+unknown\", \"azureml-pipeline\": \"1.20.0\", \"azureml-pipeline-steps\": \"1.20.0\", \"azureml-pipeline-core\": \"1.20.0\", \"azureml-opendatasets\": \"1.20.0\", \"azureml-model-management-sdk\": \"1.0.1b6.post1\", \"azureml-mlflow\": \"1.20.0.post1\", \"azureml-interpret\": \"1.20.0\", \"azureml-explain-model\": \"1.20.0\", \"azureml-defaults\": \"1.20.0\", \"azureml-dataset-runtime\": \"1.20.0\", \"azureml-dataprep\": \"2.7.3\", \"azureml-dataprep-rslex\": \"1.5.0\", \"azureml-dataprep-native\": \"27.0.0\", \"azureml-datadrift\": \"1.20.0\", \"azureml-core\": \"1.20.0\", \"azureml-contrib-services\": \"1.20.0\", \"azureml-contrib-server\": \"1.20.0\", \"azureml-contrib-reinforcementlearning\": \"1.20.0\", \"azureml-contrib-pipeline-steps\": \"1.20.0\", \"azureml-contrib-notebook\": \"1.20.0\", \"azureml-contrib-interpret\": \"1.20.0\", \"azureml-contrib-gbdt\": \"1.20.0\", \"azureml-contrib-fairness\": \"1.20.0\", \"azureml-contrib-dataset\": \"1.20.0\", \"azureml-cli-common\": \"1.20.0\", \"azureml-automl-runtime\": \"1.20.0\", \"azureml-automl-core\": \"1.20.0\", \"azureml-accel-models\": \"1.20.0\"}',\n",
       "  '_aml_system_scenario_identification': 'Remote.Parent',\n",
       "  'ClientType': 'SDK',\n",
       "  'environment_cpu_name': 'AzureML-AutoML',\n",
       "  'environment_cpu_label': 'prod',\n",
       "  'environment_gpu_name': 'AzureML-AutoML-GPU',\n",
       "  'environment_gpu_label': 'prod',\n",
       "  'root_attribution': 'automl',\n",
       "  'attribution': 'AutoML',\n",
       "  'Orchestrator': 'AutoML',\n",
       "  'CancelUri': 'https://southcentralus.experiments.azureml.net/jasmine/v1.0/subscriptions/2c48c51c-bd47-40d4-abbe-fb8eabd19c8c/resourceGroups/aml-quickstarts-137658/providers/Microsoft.MachineLearningServices/workspaces/quick-starts-ws-137658/experimentids/a5a02b58-3831-489b-abd2-237f447bb033/cancel/AutoML_f9cbc5c2-03b1-4f55-bdce-6ce77f90673b',\n",
       "  'ClientSdkVersion': '1.21.0',\n",
       "  'snapshotId': '00000000-0000-0000-0000-000000000000',\n",
       "  'SetupRunId': 'AutoML_f9cbc5c2-03b1-4f55-bdce-6ce77f90673b_setup',\n",
       "  'SetupRunContainerId': 'dcid.AutoML_f9cbc5c2-03b1-4f55-bdce-6ce77f90673b_setup',\n",
       "  'FeaturizationRunJsonPath': 'featurizer_container.json',\n",
       "  'FeaturizationRunId': 'AutoML_f9cbc5c2-03b1-4f55-bdce-6ce77f90673b_featurize',\n",
       "  'ProblemInfoJsonString': '{\"dataset_num_categorical\": 0, \"is_sparse\": true, \"subsampling\": false, \"dataset_classes\": 1447, \"dataset_features\": 1252, \"dataset_samples\": 10000, \"single_frequency_class_detected\": false}',\n",
       "  'ModelExplainRunId': 'AutoML_f9cbc5c2-03b1-4f55-bdce-6ce77f90673b_ModelExplain'},\n",
       " 'inputDatasets': [{'dataset': {'id': '5f265361-3774-4ccb-bc48-6ad5bd6b46fc'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'training_data', 'mechanism': 'Direct'}}],\n",
       " 'outputDatasets': [],\n",
       " 'logFiles': {},\n",
       " 'submittedBy': 'ODL_User 137658'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_ml_run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:The version of the SDK does not match the version the model was trained on.\n",
      "WARNING:root:The consistency in the result may not be guaranteed.\n",
      "WARNING:root:Package:azureml-automl-core, training version:1.21.0, current version:1.20.0\n",
      "Package:azureml-automl-runtime, training version:1.21.0, current version:1.20.0\n",
      "Package:azureml-core, training version:1.21.0.post1, current version:1.20.0\n",
      "Package:azureml-dataprep, training version:2.8.2, current version:2.7.3\n",
      "Package:azureml-dataprep-native, training version:28.0.0, current version:27.0.0\n",
      "Package:azureml-dataprep-rslex, training version:1.6.0, current version:1.5.0\n",
      "Package:azureml-dataset-runtime, training version:1.21.0, current version:1.20.0\n",
      "Package:azureml-defaults, training version:1.21.0, current version:1.20.0\n",
      "Package:azureml-interpret, training version:1.21.0, current version:1.20.0\n",
      "Package:azureml-pipeline-core, training version:1.21.0, current version:1.20.0\n",
      "Package:azureml-telemetry, training version:1.21.0, current version:1.20.0\n",
      "Package:azureml-train-automl-client, training version:1.21.0, current version:1.20.0\n",
      "Package:azureml-train-automl-runtime, training version:1.21.0, current version:1.20.0\n",
      "WARNING:root:Please ensure the version of your local conda dependencies match the version on which your model was trained in order to properly retrieve your model.\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the best run and the fitted model. \n",
    "best_run, fitted_model = auto_ml_run.get_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine performed featurization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RawFeatureName</th>\n",
       "      <th>TypeDetected</th>\n",
       "      <th>Dropped</th>\n",
       "      <th>EngineeredFeatureCount</th>\n",
       "      <th>Transformations</th>\n",
       "      <th>TransformationParams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>_id</td>\n",
       "      <td>Hashes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'Transformer1': {'Input': ['_id'], 'Transform...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>additives_n</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>No</td>\n",
       "      <td>18</td>\n",
       "      <td>[StringCast-CharGramCountVectorizer]</td>\n",
       "      <td>{'Transformer1': {'Input': ['additives_n'], 'T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nutriscore_grade</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>No</td>\n",
       "      <td>5</td>\n",
       "      <td>[StringCast-CharGramCountVectorizer]</td>\n",
       "      <td>{'Transformer1': {'Input': ['nutriscore_grade'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>salt_level</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>No</td>\n",
       "      <td>4</td>\n",
       "      <td>[StringCast-CharGramCountVectorizer]</td>\n",
       "      <td>{'Transformer1': {'Input': ['salt_level'], 'Tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fat_level</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>No</td>\n",
       "      <td>4</td>\n",
       "      <td>[StringCast-CharGramCountVectorizer]</td>\n",
       "      <td>{'Transformer1': {'Input': ['fat_level'], 'Tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>saturated_fat_level</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>No</td>\n",
       "      <td>4</td>\n",
       "      <td>[StringCast-CharGramCountVectorizer]</td>\n",
       "      <td>{'Transformer1': {'Input': ['saturated_fat_lev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sugar_level</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>No</td>\n",
       "      <td>4</td>\n",
       "      <td>[StringCast-CharGramCountVectorizer]</td>\n",
       "      <td>{'Transformer1': {'Input': ['sugar_level'], 'T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>vegan</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>[ModeCatImputer-StringCast-LabelEncoder]</td>\n",
       "      <td>{'Transformer1': {'Input': ['vegan'], 'Transfo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>palm_oil</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>[ModeCatImputer-StringCast-LabelEncoder]</td>\n",
       "      <td>{'Transformer1': {'Input': ['palm_oil'], 'Tran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>packagin_shape</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>No</td>\n",
       "      <td>29</td>\n",
       "      <td>[StringCast-CharGramCountVectorizer]</td>\n",
       "      <td>{'Transformer1': {'Input': ['packagin_shape'],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>packagin_material</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>No</td>\n",
       "      <td>28</td>\n",
       "      <td>[StringCast-CharGramCountVectorizer]</td>\n",
       "      <td>{'Transformer1': {'Input': ['packagin_material...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>vegeterian</td>\n",
       "      <td>Ignore</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'Transformer1': {'Input': ['vegeterian'], 'Tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>brand</td>\n",
       "      <td>CategoricalHash</td>\n",
       "      <td>No</td>\n",
       "      <td>1024</td>\n",
       "      <td>[StringCast-HashOneHotEncoder]</td>\n",
       "      <td>{'Transformer1': {'Input': ['brand'], 'Transfo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>categories_list</td>\n",
       "      <td>CategoricalHash</td>\n",
       "      <td>No</td>\n",
       "      <td>128</td>\n",
       "      <td>[StringCast-HashOneHotEncoder]</td>\n",
       "      <td>{'Transformer1': {'Input': ['categories_list']...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>serving_quantity_g</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>[MeanImputer, ImputationMarker]</td>\n",
       "      <td>{'Transformer1': {'Input': ['serving_quantity_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         RawFeatureName     TypeDetected Dropped  EngineeredFeatureCount  \\\n",
       "0                   _id           Hashes     Yes                       0   \n",
       "1           additives_n      Categorical      No                      18   \n",
       "2      nutriscore_grade      Categorical      No                       5   \n",
       "3            salt_level      Categorical      No                       4   \n",
       "4             fat_level      Categorical      No                       4   \n",
       "5   saturated_fat_level      Categorical      No                       4   \n",
       "6           sugar_level      Categorical      No                       4   \n",
       "7                 vegan      Categorical      No                       1   \n",
       "8              palm_oil      Categorical      No                       1   \n",
       "9        packagin_shape      Categorical      No                      29   \n",
       "10    packagin_material      Categorical      No                      28   \n",
       "11           vegeterian           Ignore     Yes                       0   \n",
       "12                brand  CategoricalHash      No                    1024   \n",
       "13      categories_list  CategoricalHash      No                     128   \n",
       "14   serving_quantity_g          Numeric      No                       2   \n",
       "\n",
       "                             Transformations  \\\n",
       "0                                         []   \n",
       "1       [StringCast-CharGramCountVectorizer]   \n",
       "2       [StringCast-CharGramCountVectorizer]   \n",
       "3       [StringCast-CharGramCountVectorizer]   \n",
       "4       [StringCast-CharGramCountVectorizer]   \n",
       "5       [StringCast-CharGramCountVectorizer]   \n",
       "6       [StringCast-CharGramCountVectorizer]   \n",
       "7   [ModeCatImputer-StringCast-LabelEncoder]   \n",
       "8   [ModeCatImputer-StringCast-LabelEncoder]   \n",
       "9       [StringCast-CharGramCountVectorizer]   \n",
       "10      [StringCast-CharGramCountVectorizer]   \n",
       "11                                        []   \n",
       "12            [StringCast-HashOneHotEncoder]   \n",
       "13            [StringCast-HashOneHotEncoder]   \n",
       "14           [MeanImputer, ImputationMarker]   \n",
       "\n",
       "                                 TransformationParams  \n",
       "0   {'Transformer1': {'Input': ['_id'], 'Transform...  \n",
       "1   {'Transformer1': {'Input': ['additives_n'], 'T...  \n",
       "2   {'Transformer1': {'Input': ['nutriscore_grade'...  \n",
       "3   {'Transformer1': {'Input': ['salt_level'], 'Tr...  \n",
       "4   {'Transformer1': {'Input': ['fat_level'], 'Tra...  \n",
       "5   {'Transformer1': {'Input': ['saturated_fat_lev...  \n",
       "6   {'Transformer1': {'Input': ['sugar_level'], 'T...  \n",
       "7   {'Transformer1': {'Input': ['vegan'], 'Transfo...  \n",
       "8   {'Transformer1': {'Input': ['palm_oil'], 'Tran...  \n",
       "9   {'Transformer1': {'Input': ['packagin_shape'],...  \n",
       "10  {'Transformer1': {'Input': ['packagin_material...  \n",
       "11  {'Transformer1': {'Input': ['vegeterian'], 'Tr...  \n",
       "12  {'Transformer1': {'Input': ['brand'], 'Transfo...  \n",
       "13  {'Transformer1': {'Input': ['categories_list']...  \n",
       "14  {'Transformer1': {'Input': ['serving_quantity_...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Retrieve automatic featurization details (FeaturizationInfoProvider):\n",
    "#  'datatransformer' - for regression and classigication\n",
    "#  'timeseriestransformer' - for forecasting\n",
    "featurizer = fitted_model.named_steps['datatransformer']\n",
    "#is_user_friendly=False to get more detailed formation\n",
    "featurization_summary = featurizer.get_featurization_summary(is_user_friendly=False)\n",
    "pd.DataFrame(data=featurization_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve column stats and feature type summary\n",
    "stats_n_ft_summary = featurizer.get_stats_feature_type_summary()\n",
    "pd.DataFrame(data=stats_n_ft_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# Helper function copied from Azure tutorial \n",
    "# https://docs.microsoft.com/en-us/azure/machine-learning/how-to-configure-auto-features#scaling-and-normalization\n",
    "def print_model(model, prefix=\"\"):\n",
    "    for step in model.steps:\n",
    "        print(prefix + step[0])\n",
    "        if hasattr(step[1], 'estimators') and hasattr(step[1], 'weights'):\n",
    "            pprint({'estimators': list(\n",
    "                e[0] for e in step[1].estimators), 'weights': step[1].weights})\n",
    "            print()\n",
    "            for estimator in step[1].estimators:\n",
    "                print_model(estimator[1], estimator[0] + ' - ')\n",
    "        else:\n",
    "            pprint(step[1].get_params())\n",
    "            print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model step details:\n",
      "\n",
      "datatransformer\n",
      "{'enable_dnn': None,\n",
      " 'enable_feature_sweeping': None,\n",
      " 'feature_sweeping_config': None,\n",
      " 'feature_sweeping_timeout': None,\n",
      " 'featurization_config': None,\n",
      " 'force_text_dnn': None,\n",
      " 'is_cross_validation': None,\n",
      " 'is_onnx_compatible': None,\n",
      " 'logger': None,\n",
      " 'observer': None,\n",
      " 'task': None,\n",
      " 'working_dir': None}\n",
      "\n",
      "MaxAbsScaler\n",
      "{'copy': True}\n",
      "\n",
      "GradientBoostingRegressor\n",
      "{'alpha': 0.9,\n",
      " 'ccp_alpha': 0.0,\n",
      " 'criterion': 'mse',\n",
      " 'init': None,\n",
      " 'learning_rate': 0.1,\n",
      " 'loss': 'huber',\n",
      " 'max_depth': 1,\n",
      " 'max_features': 'log2',\n",
      " 'max_leaf_nodes': None,\n",
      " 'min_impurity_decrease': 0.0,\n",
      " 'min_impurity_split': None,\n",
      " 'min_samples_leaf': 0.15874989977926784,\n",
      " 'min_samples_split': 0.02180025323490051,\n",
      " 'min_weight_fraction_leaf': 0.0,\n",
      " 'n_estimators': 100,\n",
      " 'n_iter_no_change': None,\n",
      " 'presort': 'deprecated',\n",
      " 'random_state': None,\n",
      " 'subsample': 0.7999999999999999,\n",
      " 'tol': 0.0001,\n",
      " 'validation_fraction': 0.1,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Model step details:\\n')\n",
    "print_model(fitted_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve the best model in ONNX format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the best model in ONNX format\n",
    "best_run, onnx_model = auto_ml_run.get_output(return_onnx_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.automl.runtime.onnx_convert import OnnxConverter\n",
    "# Save the model localy (where the notebook is running)\n",
    "#onnx_file_path = \"./best_model_openfoodfacts.onnx\"\n",
    "#OnnxConverter.save_onnx_model(onnx_model, onnx_file_path)\n",
    "best_run.download_file('outputs/model.onnx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1599254249203
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Register the folder (and all files in it) as a model named 'best-model-automl-bankmarketing' under the workspace\n",
    "model_automl = best_run.register_model(model_name='best-model-openfoodfacts-onnx',\n",
    "                                    model_path='outputs/model.onnx',\n",
    "                                    sample_input_dataset = dataset,\n",
    "                                    model_framework=Model.Framework.ONNX, # Framework used to create the model.\n",
    "                                    model_framework_version='1.3',      # Version of ONNX used to create the model.\n",
    "                                    description='Onnx openfoodfacts model')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_name = 'onnx-openfoodfacts-service'\n",
    "service = Model.deploy(ws, service_name, [model_automl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import Webservice, AciWebservice\n",
    "from azureml.core.model import Model\n",
    "\n",
    "print(\"Prepare ACI deployment configuration\")\n",
    "# Enable application insights\n",
    "config = AciWebservice.deploy_configuration(cpu_cores = 1, \n",
    "                                            memory_gb = 1,\n",
    "                                            enable_app_insights=True,\n",
    "                                            auth_enabled=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.model import InferenceConfig\n",
    "\n",
    "# get the 'AzureML-AutoML' curated environment used to create the model\n",
    "env = Environment.get(workspace=ws, name=\"AzureML-AutoML\")\n",
    "# creating inference configuration with the scoring file generated by AutoML run\n",
    "inference_config = InferenceConfig(entry_script=auto_ml_directory + '/outputs/scoring_file_v_1_0_0.py',                                               environment=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Deploy the model to ACI\")\n",
    "# deploying to ACI using default environment and the generated  scoring script\n",
    "# Model.get_model('best-model-automl-bankmarketing')\n",
    "service = Model.deploy(workspace=ws, name = 'best-model-service', models=[model_automl],\n",
    "                       overwrite=True, deployment_config=config, inference_config=inference_config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service.wait_for_deployment(show_output = True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Scoring URI: {service.scoring_uri}\")\n",
    "print(f\"Swagger URI: {service.swagger_uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = service.get_logs()\n",
    "\n",
    "for line in logs.split('\\n'):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "sanpil"
   }
  ],
  "categories": [
   "how-to-use-azureml",
   "machine-learning-pipelines",
   "intro-to-pipelines"
  ],
  "category": "tutorial",
  "compute": [
   "AML Compute"
  ],
  "datasets": [
   "Custom"
  ],
  "deployment": [
   "None"
  ],
  "exclude_from_index": false,
  "framework": [
   "Automated Machine Learning"
  ],
  "friendly_name": "How to use AutoMLStep with AML Pipelines",
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "order_index": 11,
  "star_tag": [
   "featured"
  ],
  "tags": [
   "None"
  ],
  "task": "Demonstrates the use of AutoMLStep"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}